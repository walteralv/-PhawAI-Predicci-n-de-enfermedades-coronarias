{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import janitor\n",
    "from pathlib import Path\n",
    "import missingno\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy\n",
    "import sklearn.compose\n",
    "import sklearn.impute\n",
    "import sklearn.preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.set_theme(\n",
    "    rc={\n",
    "      \"figure.figsize\": (8, 6)\n",
    "    }\n",
    ")\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data\")\n",
    "train_path = Path(\"data\", \"train.csv\")\n",
    "test_path = Path(\"data\", \"test_public.csv\")\n",
    "test_private_path = Path(\"data\", \"test_private.csv\")\n",
    "\n",
    "train_parquet_path = Path(\"data\", \"train.parquet\")\n",
    "test_parquet_path = Path(\"data\", \"test_public.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(train_path)  \n",
    "test_df = pd.read_csv(test_path)\n",
    "test_private_df = pd.read_csv(test_private_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(train_parquet_path).drop(columns=[\"ID\"])\n",
    "# test_df = pd.read_parquet(test_parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"CHD_OR_MI\"\n",
    "numerical_cols = [\"AGE\", \"BMI\"]\n",
    "categorical_cols = list(set(train_df.columns) - set(numerical_cols) - set([\"ID\", \"CHD_OR_MI\"]))\n",
    "train_df[categorical_cols] = train_df[categorical_cols].astype(\"category\")\n",
    "test_df[categorical_cols] = test_df[categorical_cols].astype(\"category\")\n",
    "test_private_df[categorical_cols] = test_private_df[categorical_cols].astype(\"category\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputerG:\n",
    "    def __init__(self):\n",
    "        self.num_imputer = sklearn.impute.SimpleImputer(strategy=\"median\")\n",
    "        self.cat_imputer = sklearn.impute.SimpleImputer(strategy=\"most_frequent\")\n",
    "    \n",
    "    def fit(self, df):\n",
    "        self.num_imputer.fit(df[numerical_cols])\n",
    "        self.cat_imputer.fit(df[categorical_cols])\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, df):\n",
    "        df.loc[:, numerical_cols] = self.num_imputer.fit_transform(df[numerical_cols])\n",
    "        df.loc[:, categorical_cols] = self.cat_imputer.fit_transform(df[categorical_cols])\n",
    "        return df\n",
    "\n",
    "    def transform(self, df):\n",
    "        df.loc[:, numerical_cols] = self.num_imputer.transform(df[numerical_cols])\n",
    "        df.loc[:, categorical_cols] = self.cat_imputer.transform(df[categorical_cols])\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local imputer class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_class_0 = train_df.query(\"CHD_OR_MI == 0\").copy()\n",
    "\n",
    "# local_class_0_imputer = sklearn.impute.KNNImputer()\n",
    "# train_df_class_0 = pd.DataFrame(\n",
    "#     local_class_0_imputer.fit_transform(train_df_class_0),\n",
    "#     columns=train_df.columns,\n",
    "#     index=train_df_class_0.index  # Preservar el índice original\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local imputer class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_class_1 = train_df.query(\"CHD_OR_MI == 1\").copy()\n",
    "\n",
    "# local_class_1_imputer = ImputerG()\n",
    "# train_df_class_1 = local_class_1_imputer.fit_transform(train_df_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.concat([train_df_class_0, train_df_class_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_imputer = ImputerG()\n",
    "train_df = global_imputer.fit_transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = global_imputer.transform(test_df)\n",
    "test_private_df = global_imputer.transform(test_private_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['CHD_OR_MI'])\n",
    "y_train = train_df['CHD_OR_MI']\n",
    "\n",
    "X_test = test_df.drop(columns=['CHD_OR_MI', 'ID'])\n",
    "y_test = test_df['CHD_OR_MI']\n",
    "\n",
    "X_test_private = test_private_df.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mango\\projects\\prediccion-de-sufrir-enfermedades-coronarias\\myenv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mango\\projects\\prediccion-de-sufrir-enfermedades-coronarias\\myenv\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# Balanceo con SMOTEENN\n",
    "smote_enn = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote_enn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_balanced, y_train_balanced = X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHD_OR_MI\n",
       "1.0    0.91374\n",
       "0.0    0.08626\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_balanced.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mango\\projects\\prediccion-de-sufrir-enfermedades-coronarias\\myenv\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The LGBMClassifier or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 729 candidates, totalling 2187 fits\n",
      "[LightGBM] [Info] Number of positive: 193733, number of negative: 18289\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 402\n",
      "[LightGBM] [Info] Number of data points in the train set: 212022, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.913740 -> initscore=2.360181\n",
      "[LightGBM] [Info] Start training from score 2.360181\n",
      "Mejores Hiperparámetros: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 8, 'n_estimators': 500, 'num_leaves': 63, 'subsample': 0.6}\n",
      "Mejor umbral para F1-Score: 0.16\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.01      0.01      3532\n",
      "         1.0       0.92      1.00      0.96     39874\n",
      "\n",
      "    accuracy                           0.92     43406\n",
      "   macro avg       0.78      0.50      0.48     43406\n",
      "weighted avg       0.90      0.92      0.88     43406\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   20  3512]\n",
      " [   11 39863]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Espacio de hiperparámetros para buscar\n",
    "param_grid = {\n",
    "    'num_leaves': [15, 31, 63],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Configuración del modelo LGBM base\n",
    "lgbm_model = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Configurar GridSearchCV con F1-Score como métrica\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lgbm_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(f1_score, average='macro'),\n",
    "    cv=3,  # Validación cruzada con 3 particiones\n",
    "    verbose=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ejecutar la búsqueda\n",
    "grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Obtener los mejores hiperparámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Mejores Hiperparámetros: {best_params}\")\n",
    "\n",
    "# Entrenar el modelo con los mejores parámetros\n",
    "best_lgbm_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicciones de probabilidades\n",
    "y_pred_proba = best_lgbm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Ajuste del umbral basado en F1-Score\n",
    "thresholds = np.linspace(0.1, 0.9, 100)\n",
    "f1_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_temp = (y_pred_proba >= threshold).astype(int)\n",
    "    f1_scores.append(f1_score(y_test, y_pred_temp))\n",
    "\n",
    "# Encontrar el mejor umbral\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "print(f\"Mejor umbral para F1-Score: {best_threshold:.2f}\")\n",
    "\n",
    "# Predicciones finales con el mejor umbral\n",
    "y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "# Evaluación final\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Obtener la importancia de las características\n",
    "# feature_importances = model.get_feature_importance(prettified=True)\n",
    "\n",
    "# # Mostrar las importancias\n",
    "# print(feature_importances)\n",
    "model=best_lgbm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_private_pred = model.predict_proba(X_test_private)[:, 1]\n",
    "y_test_private_pred = (y_test_private_pred >= best_threshold).astype(int)\n",
    "submission_private = pd.DataFrame({\n",
    "    \"ID\": test_private_df[\"ID\"],\n",
    "    \"CHD_OR_MI\": y_test_private_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_public = pd.DataFrame({\n",
    "  \"ID\": test_df[\"ID\"],\n",
    "  \"CHD_OR_MI\": y_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CHD_OR_MI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PID2022_152435</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PID2022_299594</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PID2022_065147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PID2022_333651</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PID2022_317306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86807</th>\n",
       "      <td>PID2022_256399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86808</th>\n",
       "      <td>PID2022_326390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86809</th>\n",
       "      <td>PID2022_178405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86810</th>\n",
       "      <td>PID2022_220522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86811</th>\n",
       "      <td>PID2022_410066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86812 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  CHD_OR_MI\n",
       "0      PID2022_152435          1\n",
       "1      PID2022_299594          1\n",
       "2      PID2022_065147          1\n",
       "3      PID2022_333651          1\n",
       "4      PID2022_317306          1\n",
       "...               ...        ...\n",
       "86807  PID2022_256399          1\n",
       "86808  PID2022_326390          1\n",
       "86809  PID2022_178405          1\n",
       "86810  PID2022_220522          1\n",
       "86811  PID2022_410066          1\n",
       "\n",
       "[86812 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.concat([submission_private, submission_public] ,ignore_index=True)\n",
    "# submission_df[\"CHD_OR_MI\"] = submission_df[\"CHD_OR_MI\"].astype\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHD_OR_MI\n",
       "1.0    0.918629\n",
       "0.0    0.081371\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHD_OR_MI\n",
       "1    0.999332\n",
       "0    0.000668\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df[\"CHD_OR_MI\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
