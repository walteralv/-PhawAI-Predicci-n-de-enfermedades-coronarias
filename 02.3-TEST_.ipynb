{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import janitor\n",
    "from pathlib import Path\n",
    "import missingno\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from catboost.core import CatBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.set_theme(\n",
    "    rc={\n",
    "      \"figure.figsize\": (8, 6)\n",
    "    }\n",
    ")\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data\")\n",
    "train_path = Path(\"data\", \"train.csv\")\n",
    "test_path = Path(\"data\", \"test_public.csv\")\n",
    "test_private_path = Path(\"data\", \"test_private.csv\")\n",
    "\n",
    "train_parquet_path = Path(\"data\", \"train.parquet\")\n",
    "test_parquet_path = Path(\"data\", \"test_public.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(train_path)  \n",
    "test_df = pd.read_csv(test_path)\n",
    "test_private_df = pd.read_csv(test_private_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(train_parquet_path).drop(columns=[\"ID\"])\n",
    "# test_df = pd.read_parquet(test_parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no hago esto mi PC Explota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"CHD_OR_MI\"\n",
    "numerical_cols = [\"AGE\", \"BMI\"]\n",
    "categorical_cols = list(set(train_df.columns) - set(numerical_cols) - set([\"ID\", \"CHD_OR_MI\"]))\n",
    "# categorical_cols = [\"SEX\",\"CANCER\",\"DIFFICULTY_WALKING\", \"HIV\", \"SMOKE\", \"MENTAL_HEALTH\"]\n",
    "features_cols = numerical_cols + categorical_cols\n",
    "train_df[categorical_cols] = train_df[categorical_cols].astype(\"category\")\n",
    "test_df[categorical_cols] = test_df[categorical_cols].astype(\"category\")\n",
    "test_private_df[categorical_cols] = test_private_df[categorical_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['CHD_OR_MI'])\n",
    "y_train = train_df['CHD_OR_MI']\n",
    "\n",
    "X_test = test_df.drop(columns=['CHD_OR_MI', 'ID'])\n",
    "y_test = test_df['CHD_OR_MI']\n",
    "\n",
    "X_test_private = test_private_df.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class BMITransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, \n",
    "                 bins=[0, 20, 25, 30, 35, 40, np.inf],\n",
    "                 labels=[1, 2, 3, 4, 5, 6]):\n",
    "                         \n",
    "                #  labels=[\"Underweight\", \"Normal\", \"Overweight\", \"Obesity I\", \n",
    "                        #  \"Obesity II\", \"Extreme Obesity\"]):\n",
    "        self.bins = bins\n",
    "        self.labels = labels\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.astype(float)\n",
    "\n",
    "        # Dividir por 100 para desescalar\n",
    "        X_real = X / 100.0\n",
    "\n",
    "        # Binning con pandas cut\n",
    "        # pd.cut retorna Series categ√≥rica, la convertimos a array\n",
    "        X_binned = pd.cut(\n",
    "            X_real,\n",
    "            bins=self.bins,\n",
    "            labels=self.labels,\n",
    "            include_lowest=True\n",
    "        )\n",
    "\n",
    "        # Retornamos como un array de shape (n_samples, 1)\n",
    "        return np.array(X_binned).reshape(-1, 1)\n",
    "\n",
    "\n",
    "class AGETransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self,\n",
    "                 bins=[0, 20, 25 , 35, 50, 65, np.inf],\n",
    "                 labels=[1, 2, 3, 4, 5, 6]):\n",
    "        self.bins = bins\n",
    "        self.labels = labels\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Espera que X sea un array/serie de una sola columna (AGE).\n",
    "        \"\"\"\n",
    "        X = X.astype(float)  # Asegurarse de tener float\n",
    "        X_binned = pd.cut(\n",
    "            X,\n",
    "            bins=self.bins,\n",
    "            labels=self.labels,\n",
    "            include_lowest=True\n",
    "        )\n",
    "        return np.array(X_binned).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_pipeline = Pipeline(steps=[\n",
    "    (\"bmi_transformer\", BMITransformer()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    # (\"onehot\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Pipeline para binning de AGE\n",
    "age_pipeline = Pipeline(steps=[\n",
    "    (\"age_transformer\", AGETransformer()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    # (\"onehot\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    # (\"onehot\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"bmi_bin\", bmi_pipeline, \"BMI\"),           # Aplica a la col BMI\n",
    "        (\"age_bin\", age_pipeline, \"AGE\"), \n",
    "        # (\"num\", numerical_transformer, numerical_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "X_test_private_processed = preprocessor.transform(X_test_private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = pd.DataFrame(X_train_processed, columns=features_cols)\n",
    "X_test_processed = pd.DataFrame(X_test_processed, columns=features_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_bal, y_train_bal = smote.fit_resample(X_train_processed, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_bal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8578876\ttotal: 732ms\tremaining: 12m 11s\n",
      "200:\tlearn: 0.9034835\ttotal: 3m 43s\tremaining: 14m 47s\n",
      "400:\tlearn: 0.9200984\ttotal: 7m 46s\tremaining: 11m 36s\n",
      "600:\tlearn: 0.9302717\ttotal: 12m 19s\tremaining: 8m 10s\n",
      "800:\tlearn: 0.9377165\ttotal: 16m 43s\tremaining: 4m 9s\n",
      "999:\tlearn: 0.9434925\ttotal: 21m 22s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x214767a0800>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='F1',\n",
    "    random_seed=52,\n",
    "    verbose=200,\n",
    "    class_weights=[5,1],\n",
    "    depth=15,               \n",
    "    iterations=1000,       \n",
    "    learning_rate=0.01,\n",
    "    l2_leaf_reg=5,        # Regularizaci√≥n L2 (controla sobreajuste)\n",
    "    # subsample=0.8,        # Selecciona ~80% de muestras en cada √°rbol (bagging)\n",
    "    # bootstrap_type='Bernoulli',  # Estrategia de muestreo m√°s estable\n",
    "    # random_strength=2,    # Controla la aleatoriedad de splits\n",
    "    od_type='Iter',       # Early stopping: deja de entrenar si no mejora en X iteraciones seguidas\n",
    "    od_wait=50,           # Paciencia: espera 50 iteraciones sin mejora\n",
    "    # use_best_model=True   \n",
    "\n",
    ")\n",
    "model.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.9369652742828385\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.31      0.33      0.32      3532\n",
      "         1.0       0.94      0.93      0.94     39874\n",
      "\n",
      "    accuracy                           0.88     43406\n",
      "   macro avg       0.62      0.63      0.63     43406\n",
      "weighted avg       0.89      0.88      0.89     43406\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1161  2371]\n",
      " [ 2639 37235]]\n"
     ]
    }
   ],
   "source": [
    "# Predicciones y evaluaci√≥n\n",
    "y_pred = model.predict(X_test_processed)\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred)}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor umbral para F1-Score: 0.14\n",
      "F1-Score: 0.957736320800077\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.01      0.03      3532\n",
      "         1.0       0.92      1.00      0.96     39874\n",
      "\n",
      "    accuracy                           0.92     43406\n",
      "   macro avg       0.76      0.51      0.49     43406\n",
      "weighted avg       0.89      0.92      0.88     43406\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   52  3480]\n",
      " [   36 39838]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# Ajuste del umbral\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "f1_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_temp = (y_pred_proba >= threshold).astype(int)\n",
    "    f1_scores.append(f1_score(y_test, y_pred_temp))\n",
    "\n",
    "# Mejor umbral basado en F1-Score\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "print(f\"Mejor umbral para F1-Score: {best_threshold:.2f}\")\n",
    "# Predicciones finales con el mejor umbral\n",
    "y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred)}\")\n",
    "\n",
    "# Evaluaci√≥n final\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_private_pred = model.predict_proba(X_test_private_processed)[:, 1]\n",
    "# y_test_private_pred = (y_test_private_pred >= best_threshold).astype(int)\n",
    "y_test_private_pred = model.predict(X_test_private_processed)\n",
    "\n",
    "submission_private = pd.DataFrame({\n",
    "    \"ID\": test_private_df[\"ID\"],\n",
    "    \"CHD_OR_MI\": y_test_private_pred\n",
    "})\n",
    "\n",
    "submission_public = pd.DataFrame({\n",
    "  \"ID\": test_df[\"ID\"],\n",
    "  \"CHD_OR_MI\": y_pred\n",
    "})\n",
    "submission_df = pd.concat([submission_private, submission_public] ,ignore_index=True)\n",
    "# submission_df[\"CHD_OR_MI\"] = submission_df[\"CHD_OR_MI\"].astype\n",
    "submission_df\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMI</td>\n",
       "      <td>9.136773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FRIED_POTATOES</td>\n",
       "      <td>6.922738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGE</td>\n",
       "      <td>6.899310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEX</td>\n",
       "      <td>6.357314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MENTAL_HEALTH</td>\n",
       "      <td>5.735456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HIGH_CHOLESTEROL</td>\n",
       "      <td>5.728742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PHYSICAL_HEALTH</td>\n",
       "      <td>5.515190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMOKE</td>\n",
       "      <td>5.181498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BLOOD_PRESSURE</td>\n",
       "      <td>5.017767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FRUITS</td>\n",
       "      <td>4.747164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ETHNICITY</td>\n",
       "      <td>4.120071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ARTHRITIS</td>\n",
       "      <td>3.952265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DIABETES</td>\n",
       "      <td>3.813261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>VEGETABLES</td>\n",
       "      <td>3.638300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>E_CIGARETTES</td>\n",
       "      <td>3.448422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HIV</td>\n",
       "      <td>3.352582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HEALTH</td>\n",
       "      <td>3.168285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PHYSICAL_ACTIVITIES</td>\n",
       "      <td>3.132238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DIFFICULTY_WALKING</td>\n",
       "      <td>2.235971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DEPRESSIVE_DISORDER</td>\n",
       "      <td>1.646207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BRONCHITIS</td>\n",
       "      <td>1.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CANCER</td>\n",
       "      <td>1.163341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>HEAVY_DRINKERS</td>\n",
       "      <td>1.003592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SKIN_CANCER</td>\n",
       "      <td>0.985515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KIDNEY_DISEASE</td>\n",
       "      <td>0.890947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TABACCO_PRODUCTS</td>\n",
       "      <td>0.566023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature Id  Importances\n",
       "0                   BMI     9.136773\n",
       "1        FRIED_POTATOES     6.922738\n",
       "2                   AGE     6.899310\n",
       "3                   SEX     6.357314\n",
       "4         MENTAL_HEALTH     5.735456\n",
       "5      HIGH_CHOLESTEROL     5.728742\n",
       "6       PHYSICAL_HEALTH     5.515190\n",
       "7                 SMOKE     5.181498\n",
       "8        BLOOD_PRESSURE     5.017767\n",
       "9                FRUITS     4.747164\n",
       "10            ETHNICITY     4.120071\n",
       "11            ARTHRITIS     3.952265\n",
       "12             DIABETES     3.813261\n",
       "13           VEGETABLES     3.638300\n",
       "14         E_CIGARETTES     3.448422\n",
       "15                  HIV     3.352582\n",
       "16               HEALTH     3.168285\n",
       "17  PHYSICAL_ACTIVITIES     3.132238\n",
       "18   DIFFICULTY_WALKING     2.235971\n",
       "19  DEPRESSIVE_DISORDER     1.646207\n",
       "20           BRONCHITIS     1.641026\n",
       "21               CANCER     1.163341\n",
       "22       HEAVY_DRINKERS     1.003592\n",
       "23          SKIN_CANCER     0.985515\n",
       "24       KIDNEY_DISEASE     0.890947\n",
       "25     TABACCO_PRODUCTS     0.566023"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_feature_importance(prettified=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from catboost import Pool\n",
    "\n",
    "# # Suponiendo que tienes:\n",
    "# # model (tu CatBoostClassifier ya entrenado)\n",
    "# # X_train_processed (numpy array o DataFrame)\n",
    "# # y_train (Series o array)\n",
    "\n",
    "# # 1) Crea un Pool (objeto interno de CatBoost) con tus datos\n",
    "# train_pool = Pool(data=X_train_processed, label=y_train)\n",
    "\n",
    "# # 2) Obtener valores SHAP\n",
    "# shap_values = model.get_feature_importance(\n",
    "#     type=\"ShapValues\",    # Indica que deseas valores SHAP\n",
    "#     data=train_pool\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
