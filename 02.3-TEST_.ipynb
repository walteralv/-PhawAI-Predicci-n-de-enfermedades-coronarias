{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import janitor\n",
    "from pathlib import Path\n",
    "import missingno\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from catboost.core import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.set_theme(\n",
    "    rc={\n",
    "      \"figure.figsize\": (8, 6)\n",
    "    }\n",
    ")\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data\")\n",
    "train_path = Path(\"data\", \"train.csv\")\n",
    "test_path = Path(\"data\", \"test_public.csv\")\n",
    "test_private_path = Path(\"data\", \"test_private.csv\")\n",
    "\n",
    "train_parquet_path = Path(\"data\", \"train.parquet\")\n",
    "test_parquet_path = Path(\"data\", \"test_public.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(train_path)  \n",
    "test_df = pd.read_csv(test_path)\n",
    "test_private_df = pd.read_csv(test_private_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(train_parquet_path).drop(columns=[\"ID\"])\n",
    "# test_df = pd.read_parquet(test_parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no hago esto mi PC Explota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"CHD_OR_MI\"\n",
    "numerical_cols = [\"AGE\", \"BMI\"]\n",
    "categorical_cols = list(set(train_df.columns) - set(numerical_cols) - set([\"ID\", \"CHD_OR_MI\"]))\n",
    "train_df[categorical_cols] = train_df[categorical_cols].astype(\"category\")\n",
    "test_df[categorical_cols] = test_df[categorical_cols].astype(\"category\")\n",
    "test_private_df[categorical_cols] = test_private_df[categorical_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['CHD_OR_MI'])\n",
    "y_train = train_df['CHD_OR_MI']\n",
    "\n",
    "X_test = test_df.drop(columns=['CHD_OR_MI', 'ID'])\n",
    "y_test = test_df['CHD_OR_MI']\n",
    "\n",
    "X_test_private = test_private_df.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, numerical_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "    ],\n",
    "    remainder=\"passthrough\"  # Si deseas dejar columnas adicionales sin tocar\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "X_test_private_processed = preprocessor.transform(X_test_private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_names = preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"].get_feature_names_out(categorical_cols)\n",
    "all_feature_names = numerical_cols + list(categorical_feature_names)\n",
    "X_train_processed = pd.DataFrame(X_train_processed, columns=all_feature_names)\n",
    "X_test_processed = pd.DataFrame(X_test_processed, columns=all_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mango\\projects\\prediccion-de-sufrir-enfermedades-coronarias\\myenv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mango\\projects\\prediccion-de-sufrir-enfermedades-coronarias\\myenv\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTETomek or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mango\\projects\\prediccion-de-sufrir-enfermedades-coronarias\\myenv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mango\\projects\\prediccion-de-sufrir-enfermedades-coronarias\\myenv\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mango\\projects\\prediccion-de-sufrir-enfermedades-coronarias\\myenv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mango\\projects\\prediccion-de-sufrir-enfermedades-coronarias\\myenv\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The TomekLinks or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "smt_tomek = SMOTETomek(random_state=42)\n",
    "X_train_bal, y_train_bal = smt_tomek.fit_resample(X_train_processed, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fold, X_val_fold, y_train_fold, y_val_fold = train_test_split(\n",
    "    X_train_bal, \n",
    "    y_train_bal, \n",
    "    test_size=0.2,\n",
    "    random_state=52, \n",
    "    stratify=y_train_bal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7699575\ttest: 0.7716070\tbest: 0.7716070 (0)\ttotal: 72.6ms\tremaining: 1m 12s\n",
      "100:\tlearn: 0.9384710\ttest: 0.9380723\tbest: 0.9380723 (100)\ttotal: 7.54s\tremaining: 1m 7s\n",
      "200:\tlearn: 0.9489704\ttest: 0.9484990\tbest: 0.9484990 (200)\ttotal: 13.7s\tremaining: 54.5s\n",
      "300:\tlearn: 0.9519242\ttest: 0.9504090\tbest: 0.9504208 (299)\ttotal: 20.2s\tremaining: 46.9s\n",
      "400:\tlearn: 0.9535374\ttest: 0.9508295\tbest: 0.9508295 (400)\ttotal: 27.5s\tremaining: 41.1s\n",
      "500:\tlearn: 0.9545947\ttest: 0.9508993\tbest: 0.9509753 (483)\ttotal: 33.8s\tremaining: 33.7s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9510059172\n",
      "bestIteration = 508\n",
      "\n",
      "Shrink model to first 509 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x15d0c91be00>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='F1',\n",
    "    random_seed=52,\n",
    "    verbose=100,\n",
    "    depth=7,\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    l2_leaf_reg=3,\n",
    "    subsample=0.8,\n",
    "    bootstrap_type='Bernoulli',\n",
    "    random_strength=2,\n",
    "    border_count=128,\n",
    "    od_type='Iter',             # Activar early stopping\n",
    "    od_wait=50,                 # Espera 50 iteraciones sin mejora\n",
    "    use_best_model=True,         # Usa el mejor modelo según eval_set\n",
    "    verbose=100,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_fold, \n",
    "    y_train_fold,\n",
    "    eval_set=(X_val_fold, y_val_fold)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.9565901988808411\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.09      0.16      3532\n",
      "         1.0       0.93      0.99      0.96     39874\n",
      "\n",
      "    accuracy                           0.92     43406\n",
      "   macro avg       0.69      0.54      0.56     43406\n",
      "weighted avg       0.89      0.92      0.89     43406\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  333  3199]\n",
      " [  385 39489]]\n"
     ]
    }
   ],
   "source": [
    "# Predicciones y evaluación\n",
    "y_pred = model.predict(X_test_processed)\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred)}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor umbral para F1-Score: 0.38\n",
      "F1-Score: 0.957970246978961\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.03      0.06      3532\n",
      "         1.0       0.92      1.00      0.96     39874\n",
      "\n",
      "    accuracy                           0.92     43406\n",
      "   macro avg       0.76      0.52      0.51     43406\n",
      "weighted avg       0.90      0.92      0.89     43406\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  118  3414]\n",
      " [   78 39796]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# Ajuste del umbral\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "f1_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_temp = (y_pred_proba >= threshold).astype(int)\n",
    "    f1_scores.append(f1_score(y_test, y_pred_temp))\n",
    "\n",
    "# Mejor umbral basado en F1-Score\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "print(f\"Mejor umbral para F1-Score: {best_threshold:.2f}\")\n",
    "# Predicciones finales con el mejor umbral\n",
    "y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred)}\")\n",
    "\n",
    "# Evaluación final\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_private_pred = model.predict_proba(X_test_private_processed)[:, 1]\n",
    "# y_test_private_pred = (y_test_private_pred >= best_threshold).astype(int)\n",
    "y_test_private_pred = model.predict(X_test_private_processed)\n",
    "\n",
    "submission_private = pd.DataFrame({\n",
    "    \"ID\": test_private_df[\"ID\"],\n",
    "    \"CHD_OR_MI\": y_test_private_pred\n",
    "})\n",
    "\n",
    "submission_public = pd.DataFrame({\n",
    "  \"ID\": test_df[\"ID\"],\n",
    "  \"CHD_OR_MI\": y_pred\n",
    "})\n",
    "submission_df = pd.concat([submission_private, submission_public] ,ignore_index=True)\n",
    "# submission_df[\"CHD_OR_MI\"] = submission_df[\"CHD_OR_MI\"].astype\n",
    "submission_df\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
